<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JUST LAD</title>
  
  <subtitle>记载互联网感悟</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-10-13T08:30:41.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>吴三水</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>AI创业：始于外包，终于何？</title>
    <link href="http://yoursite.com/2017/10/13/AI%E5%88%9B%E4%B8%9A%EF%BC%9A%E5%A7%8B%E4%BA%8E%E5%A4%96%E5%8C%85%EF%BC%8C%E7%BB%88%E4%BA%8E%E4%BD%95%EF%BC%9F/"/>
    <id>http://yoursite.com/2017/10/13/AI创业：始于外包，终于何？/</id>
    <published>2017-10-13T08:14:40.000Z</published>
    <updated>2017-10-13T08:30:41.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>“你们AI看着像外包，听着像外包，本质还是外包。” “你以为我想？”</p></blockquote><p>编者按：本文来自微信公众号“甲子光年”（ID：jazzyear），作者金丝猴，编辑甲小姐，36氪经授权发布。</p><a id="more"></a> <p>前段时间，我与某AI创业公司联合创始人S君聊天，他给我讲了一个听起来很肉疼的真实故事。</p><p>S君所在的公司主攻深度学习技术，他们和某银行客户合作一个零售客户成交预测项目。</p><p>洽谈初期，银行方面告诉他们：自身已积累了上千万客户历史行为的多维度的清洁数据，包括全方位客户画像、行内交易流水、行外采购数据等。</p><p>接下来，S君团队一边着手设计方案，一边进行数据对接。设计方案这条线进行得有条不紊；但数据对接方面却一再卡壳。</p><p>经过层层关卡，在项目开始一个半月后，S君的团队终于拿到银行口中“上千万且多维度的清洁数据”，结果却令人崩溃——“千万用户”中，大部分用户数据严重不符合要求，满足“多维度清洁数据”条件的只有数千人。</p><p>已经开始一个半月的原方案几乎打水漂。</p><p>团队傻眼，客户摊手，只得从头来过。</p><p>“不是傻天真地去相信。客户说有，如果你不信那就别做了呗。”我问S君是不是傻，他不屑又无奈。</p><p>“这是由多方面原因造成的：其一，银行数据保密度高，需要层层审批；其二，体制内工作效率低下；其三，银行不同部门之间的数据隔离会阻碍数据调用。往更深层次说，这会牵扯到银行内部领导的政治关系。”S君说，这些因素均不可控，但这就是现实。</p><p>对于一个像S君所在的才二十来号人的小规模创业公司来说，这无疑是人力、时间成本的惨重损失：几十个日夜的心血付诸东流，难免会挫伤团队积极性；而再进一步，这每日每夜烧的都是投资人的钱和耐心，还有创业公司的剩余寿命。</p><p>可这样的故事，每天都在上演。</p><h4 id="困于“外包”"><a href="#困于“外包”" class="headerlink" title="困于“外包”"></a>困于“外包”</h4><p><img src="http://wuqialin.com/2017-10-13-外包之痛.jpeg" alt="外包之痛"></p><p>AI创业：始于外包，终于何？</p><p>S君的故事于我，就像看了一张撕倒刺的图片——深深地肉疼。而对于身处于AI行业的一线从业者来讲，每个故事背后都是“肉包子打狗”式的时间、心血以及热情。 </p><p>一个做深度学习产品经理的老友告诉我：他们公司有40%的项目都无疾而终；另一个原阿里云的朋友则表示：阿里云很多项目做了3、4个月以后，才发现这并不是靠机器学习能解决的问题，“无疾而终率”高达50%。 </p><p>还处于baby阶段的AI创业公司虽集万千资本宠爱于一身，但高高在上的“无疾而终率”不得不让人怀疑这个市场的健康性。投资者的钱是否能够“烧得其所”？</p><p>带着这个问题寻找答案，一圈采访下来，我的结论是：</p><p>目前绝大部分to B的AI初创公司的商业模式本质是“外包”，而实际性价比却远不如一般行业的外包。</p><p>这个观点也许不讨喜，甚至得罪人。“外包”二字在技术圈的地位向来偏低，因为从传统概念上来讲，外包属于劳动密集型工种，在知乎关于“外包”的问题下，甚至有一部分网友明确表示“看不起干外包的”。</p><p>然而，纵观to B的AI企业现状，除安防领域以外，几乎没有公司能将技术以规模化、产品化的方式输出。比较大部分to B的AI初创公司业务模式和一般行业的外包者，相似性摆在眼前：</p><p>从工作流程上来看，两者共同点在于——第一步，沟通需求和可行性；第二步，工作量评估、报价、进度安排；第三步，签署项目合同；第四步，设计、研发、测试、上线；第五步，交付相关文档与源码，技术输出；第六步，提供维护、迭代等服务。</p><p>从合作方式及定价上来看，两者共同点在于——case by case；没有一套适用于所有客户的标准化定价指标；客单利润偏低；定价分歧时有发生。</p><p>从公司结构、商业模式上来看，两者共同点在于——想挣得多只能多接活儿，多接活儿只能多招人，技术被需求牵着鼻子走。</p><p>从发展空间上来看，两者共同点在于——只能N倍增长，无法实现N方增长，想象力和发展空间均被局限。</p><p>但为何说AI行业实际性价比还远不如一般行业的外包？</p><p>第一，外包的前提，是时间和成本的可预估。但就目前大多AI公司实际业务情况来看：时间、成本均不可预估，项目进行两三个月后才发现“此路不通”的情况比比皆是。</p><p>其二，人力成本是决定外包公司存活质量的重要因素。而AI行业中，成本高昂的人才争夺战从未停止，用外包收入去养天价人才，其逻辑不攻自破，后果难以估量。</p><p>由此，AI与一般行业的外包相比，共性之余，相形见绌。</p><p>行业困于外包模式，直接导致造血能力低下、已有技术无法输出、技术研发得不到支持。如果说外包只是AI生存的第一阶段，如今，投资人看指标的时节正在步步逼近——正如非洲大草原旱季来临之时，只有生命力最顽强的动物得以幸存。</p><p>原因何在？ </p><p>目前AI困于外包模式，究其原因，可分为客观规律、内因、外因三方面。</p><p>首先，客观规律：</p><p>驭势科技联合创始人兼项目部负责人彭进展告诉我，每个新技术问世所带来的产业发展都将经历“递进三阶段”：第一阶段是技术驱动，发现技术，持续钻研，早期主要以科学家、工程师、研发人员带动；第二阶段是应用驱动，技术得到认可后，通过产品化逐步落地，并应用于不同的垂直领域中，此阶段由开发工程师主要推动；第三阶段是商业模式驱动，此时，产品、技术和应用已进入成熟期，有效的商业模式创新能带来爆发式增长。</p><p>与三个阶段所对应的还有三个验证关卡：技术验证、产品验证、量产验证——目前的AI行业卡在了第二阶段。</p><p>其次，内因：</p><p>AI技术具有典型的“落地口径窄，需求不稳定”特征，这使得其行业商业化探索阶段会更加漫长。图灵机器人人才战略官黄钊在他知名的200多页PPT《人工智能产品经理的新起点》中阐述到：AI时代有两大重要特质——高维+突变。他告诉我：“正是由于这两大特质，AI领域需求的特点是：机会多、难度大、变化又快又大。”</p><p>最后，外因：</p><p>在目前AI行业中，客户的期望控制与管理是难以绕开的大坑。</p><p>客户期望由三方面所影响：对AI技术的认知、对自身条件的认知、对自身需求的认知。然而不幸的是，就目前市场现状来看，大部分客户三方面的认知都不健全。</p><p>最常见的情况是，代表客户和AI公司对接的工作人员由于以上三方面认知不健全，提供错误信息，直接导致方案在设计环节中出现偏差，严重降低工作效率。</p><p>王汉洋生于1994年，是泛化智能的CEO。在这个坑上，他很有发言权。</p><p>他本科就读于加拿大滑铁卢大学数学专业，主修计算机。刚念完大二，他便选择休学，回国创业。其公司专注于机器学习与计算机视觉，并在电力、机场、无人机控制等方向完成行业颇有竞争力的技术积累。</p><p>因为泛化智能的客户大多来自体制内的传统行业，所以对此感受深刻。“我目前没碰到任何一个客户清楚理解深度学习是什么，关于机器学习都是听罗振宇讲的。”</p><p>为此他们专门制作了一套“文风指南”，作用是在见客户的时候帮助他们正确的理解AI，消除认知偏差。“第一条，不要写任何术语。比如‘子集’，很多客户不知道什么是子集，你应该说它包括了什么东西。”</p><p>除了客户认知问题外，数据也是外因中至关重要的点。前不久，吴恩达在旧金山发表名为“AI Is the new electricity”的主题演讲，反复强调数据对于AI的重要性。他认为，普及数据统一存储是AI技术大规模使用的前提。</p><p>客户有没有数据、给不给数据、数据是否有效——将直接影响到项目或产品的效率提升。</p><h4 id="从何突围？"><a href="#从何突围？" class="headerlink" title="从何突围？"></a>从何突围？</h4><p>致力于打造通用型人工智能平台的第四范式互联网业务负责人周开拓这样认为：“纵横两条线一起推进。一方面，开发低耦合、通用型的产品，解决基础需求；另一方面，选定特定的垂直行业深扎，积累了足够深刻的认识和经验后，会发现问题变得越来越简单，方向也逐渐清晰起来，也能与竞争对手拉开距离。”</p><p>但至于纵、横两方面该如何平衡、哪些行业值得深扎，则需要根据不同企业自身的条件和战略去考量。</p><p>泛化智能王汉洋的思路则更为特别。</p><p>“我们现在就是外包模式。遇到聊得不错的投资人我会直接跟他这样讲，他要不认同这事儿，他就是不客观。”王汉洋认为，目前市场现状就是这样，摆正“外包心态”来做事是脱离外包模式的前提。</p><p>他认为，外包本身是一件非常有价值的事情——其一，用新技术帮用户解决问题是对技术的认可；其二，外包是挣钱的，“能让 AI 行业避免沾上共享经济那种荒诞烧钱的属性”；其三，外包模式下，协调多变的需求、维护客户关系这种脏活累活，正好让现在 AI 行业高谈阔论却不愿意踏踏实实做实事的风气有所改观。</p><p>王汉洋向我介绍了其公司目前的业务情况：“像电网这样的大行业客户初期客单价很低，一单在十几万元左右；如果是一次性合作的小公司，一单则从几十万到上百万不等。”</p><p>王汉洋的公司目前只有十来人，成本不高，但能同时接四个项目。“每个月只要有一单我就能盈亏平衡了，再多一单我就挣了。”公司大部分客户前期沟通时间长，而实际服务周期不到一个月，但也不乏有长达三四个月的大单子。“大单子不一样，基本来自于‘大行业、真需求’，一边赚钱一边学习实践，非常值！”</p><p>王汉洋感到的“值”和线性资本创始合伙人王淮的看法不谋而合。王淮认为，面对“真客户”，赚不赚钱不是最重要的。</p><p>“举个例子，假如你是一家做Fintech的公司，你和‘宇宙第一大行’工商银行合作，并且拿到他们核心的放贷业务，那这个客户就是‘真客户’。”王淮说，如果有这种经历，就像是把新兵放到真实战场中去操练一样，出来之后不管是能力、眼界还是信用度都会得到极大的提升，“哪怕赔钱也一定要做的！”</p><p>至于具体该如何脱离外包模式，王汉洋也没有十足把握。“得深入到产业中去，先做，做得多了才有机会突破。这个探索的过程就像是寻找树叶上的脉络一样，找到这些脉络，才能勾勒出产品的形态。”</p><p>“我用Siri好多年，到现在还经常被人当傻子。但我是做AI的，要我自己都不相信它，我为啥还做这行？当年智能手机刚出时，大家还觉得拿手机上网奇怪呢。”王汉洋觉得无论是Siri还是自己的“外包公司”，随着技术的发展和自身努力，都会变得越来越好。</p><p>“不是我精神分裂了，而是我不希望AI一直都这么像外包，或者满足于这个现状。”王汉洋说，主动去感知这些痛，是因为不想粉饰太平，而他相信，这些痛终将成为过程。</p><h4 id="始于外包，终于何？"><a href="#始于外包，终于何？" class="headerlink" title="始于外包，终于何？"></a>始于外包，终于何？</h4><p>“假如把AI创业公司的竞争看做足球世界杯，现在是小组预选赛刚开始，大部分公司在让世人知道之前就会死掉。”明势资本合伙人黄明明说。</p><p>“马太效应”、“二八定律”几乎作用于所有和人相关的领域，“到投资人看指标时，死一大片公司是很正常的事情。”王淮和黄明明持同样的观点。</p><p>对于“外包”，王淮话语犀利：“是不是外包模式是一回事，心里承不承认又是另一回事。就好像以前的gcd地下党一样，虽然你身在gmd阵营，但你内心要清楚自己的目标和阵营。要是心里面就承认了自己就是gmd，那就没得玩了。”他说，人内心的力量是很强大的，强大到足以影响到自身的行为，但承认并不是改变的必要前提。</p><p>对于经常把“这个业务不赚钱，我们要生存下去”挂在嘴边的公司，王淮基本不会再深入了解，“这样的团队其实内心已经屈服了，让他们安心的做一个外包公司不挺好？”</p><p>既然“拿着锤子找钉子”是目前AI商业化落地进程中最大的逻辑问题，王淮相信，根据各家自身的不同特点，将手中“锤子”的能力最大化，才是提高生存概率的解决之道。</p><p>作为曾经的Facebook最早的技术人员，王淮对此有深刻的思考。他认为，最终只有三种商业模式的AI公司能够发展壮大，成为行业头部公司：</p><p>其一，“工具箱化”。在向客户提供“锤子”的同时，还要配套提供“钳子”、“锯子”、“螺丝刀”。例如，Stanley Black &amp; Decker是美国一家生产并销售工业工具及安全方案的公司，如今市值已经超过200亿美金。这是一种偏传统的思路，比得是“比同行活得更久”，对团队的技术能力要求非常高，也是最难成功的一种。</p><p>其二，“自成一体化”。和“工具箱化”不同，“自成一体化”需把提供“锤子”的能力服务于客户的思路转变为，将自身“锤子”的技术用于打磨自身业务，而不是向外界输出。相当于自己开一家“五金店”，典型的成功案例如“快手”“今日头条”。</p><p>其三，“经验共享化”。将自身变为一个“工程队”，在运用“锤子”技术解决客户问题的同时积累更多的“技能点”。典型例子是AI反欺诈领域公司同盾科技，他们早期向客户提供征信黑名单的前提，需要客户把自己的黑名单给到他们，这种形式的优点在于提供技术的同时构建起自身网络化、共享化的能力。</p><p>科幻小说巨匠阿西莫夫提出过一个理论：电梯效应。大意是讲，如果给一个 1850 年的科幻作家看二十世纪曼哈顿摩天大楼的照片，当他看到一幢幢超过 20 层甚至 100 层的建筑物会怎么想？</p><p>也许你用最大的想象力却只能得出这样的结论：因为“上下楼”很难，所以每个楼都会发展出独立的经济体系；摩天大楼里也会有文明人生活的必须设施，比如餐厅，理发厅，健身房等；因为大多数人不会爬太多层，所以这些设施过几层就会循环出现；底层因为出来容易，房价要比顶层高……作家越想越细，越来越多——但当“电梯”出现时，这些假设全部变得毫无意义。</p><p>纵观过去几十年计算机历史，苹果、英特尔、微软、谷歌……所有伟大或者曾经伟大过的技术公司都因创造出了能服务于整个社会的产品。做外包不是不行，但毕竟历史上没有人因外包而伟大。而古往今来，真正的革命性技术会从底层来重塑人与人，人与社会的关系。</p><p>正如王汉洋告诉我们的：如果我们没有比前人更宏大的追求，那我们又有什么理由过的比前人更好呢？</p><p>如果AI行业止步于外包，便浪费了一个技术变得更伟大的机会。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;“你们AI看着像外包，听着像外包，本质还是外包。” “你以为我想？”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;编者按：本文来自微信公众号“甲子光年”（ID：jazzyear），作者金丝猴，编辑甲小姐，36氪经授权发布。&lt;/p&gt;
    
    </summary>
    
      <category term="互联网资讯" scheme="http://yoursite.com/categories/%E4%BA%92%E8%81%94%E7%BD%91%E8%B5%84%E8%AE%AF/"/>
    
    
      <category term="资讯" scheme="http://yoursite.com/tags/%E8%B5%84%E8%AE%AF/"/>
    
  </entry>
  
  <entry>
    <title>“测试文章，仅展示作用”</title>
    <link href="http://yoursite.com/2017/10/12/%E2%80%9C%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0%EF%BC%8C%E4%BB%85%E5%B1%95%E7%A4%BA%E4%BD%9C%E7%94%A8%E2%80%9D/"/>
    <id>http://yoursite.com/2017/10/12/“测试文章，仅展示作用”/</id>
    <published>2017-10-12T11:10:06.000Z</published>
    <updated>2017-10-12T11:30:15.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>哥伦比亚教授周以真：人工智能恐慌以及大数据威胁反思</p><p>使用不负责任的数据导致的偏见算法和严重后果，到底应该由谁负责？个人和阿里巴巴这样的企业应该用什么样的态度对待数据？以及我们该如何用科技本身保证科技的公平透明？<br>大数据文摘记者：魏子敏</p></blockquote><a id="more"></a> <p>大数据和人工智能正无可置疑地为全行业和我们的生活带来了翻天覆地的变化，在10月11日2017杭州·云栖大会的主论坛上，不同于全场众多追捧褒扬之声，来自哥伦比亚大学的周以真教授则针对大数据和人工智能可能带来的威胁进行了反思。她提出，数据会给我们带来很多好处，但是如果不负责任滥用数据和算法，会带来可怕的结果。</p><p>“我要给大家敲一个警钟，我们在使用数据过程当中不负责任的话，会有什么样的后果。” 她用FATES（命运）这个比喻的缩写来讲述了怎样有责任的使用数据，F是代表公平，A是可靠，T是透明，E是有道德，S是代表安全。演讲中周以真教授同时提出了一些引人思考的问题：使用不负责任的数据导致的偏见算法和严重后果，到底应该由谁负责？个人和阿里巴巴这样的企业应该用什么样的态度对待数据？以及我们该如何用科技本身保证科技的公平透明？</p><p>周以真现任哥伦比亚大学数据科学研究院主任，定义了计算思维。</p><p>哥伦比亚教授周以真：人工智能恐慌以及大数据威胁反思<br>哥伦比亚教授周以真在2017杭州云栖大会主论坛的演讲《Data for Good：Scary AI and Other Dangers with Big Data（大数据的好处：可怕的人工智能以及大数据的威胁）》</p><p>以下为周以真相关演讲的速记，在不改变原意的情况下有删改。</p><p>数据能够带来什么样的好处，我这里分两方面来说。</p><p>第一方面，我们要有责任的使用数据。</p><p>第二方面，我们要用数据来应对社会巨大的问题，比如说能源、环境、教育、气侯变化等等这些重大的人类命题。</p><p>但是今天我只是会去谈有责任的使用数据这一个方面，因为我们所有人都是在使用数据，我们在使用数据的目的，都是为了应对社会的挑战。我演讲的目的，给大家敲一个警钟，我们在使用数据过程当中不负责任的话，会有什么样的后果。</p><p>我想用FATES（命运）这个比喻的缩写来去讲一下怎么有责任的使用，F是代表公平，A是可靠，T是透明，E是有道德，S是代表安全。</p><p>有偏见的数据导致的问题，谁该负责任？</p><p>首先来看一下数据，我在给大家分享之前，先非常简单的讲一下典型的算法和模式，我们在用大数据为原料，进行大数据计算的时候，涉及到的一些算法和模型。我们知道机器学习和形成一种模型，有这个模型，我可以再输入新的数据，这个新的数据，经过这个模型之后，有可能产生新的结果，之后我们可以来判断和预计，这个用户有可能采购哪些商品。</p><p>我们知道数据和算法都可能是有偏见的，那么如果数据和算法是有偏见的话，那么我们的这个模型可能也会有偏见，那么我们的结果也会有偏见的。让我们来看一个实例，那么这是几年前我们看到两个小偷，在美国的法官用了这种算法来决定判断量刑过程当中是否恰当，我们看到这些自主研发的算法，在法官当中广为流行的算法，用于帮助法官去判断这些量刑。</p><p>我发现他们对于黑人和白人量刑的结果是不同的，其实结果还不仅仅于此，我们在算法当中有一些什么样的问题，这个算法本身是有偏见的，而且哈佛大学学者研究出来，这些算法有可能是可以判断的，又可能是错误的，但不可能两者兼具，实际上是不可能去判断这个风险的分数。</p><p>第二个例子，这是我的这些同事做的项目，我的这些同事研究了在Google上的广告，他们发现这些高薪的工作机会更多的会向男性网民展现，女性网民看到这些高薪的招聘广告机会会比较少，我们觉得这是不公平的。现在我们就要去思考，这个模型是否是公正的，这些分类是否是公正的，我们怎么样来确保，这个案例就引发了另外一个问题，那就是可靠性。</p><p>哥伦比亚教授周以真：人工智能恐慌以及大数据威胁反思<br>说到底，出现问题的时候，我们应该怪谁呢？</p><p>好像这个问题很难找出一个好的答案，但是我们要有担当，我们在IT界，我们是发明这些算法的人，我们是使用数据的人，我们是产生和收集这些数据的人，并且生成这些结果的人，我们要有担当。</p><p>如果你是一家企业，那么如果你是一个有责任的企业，你应该做什么，你首先可以把政策进行公布，你的隐私政策进行公布，而且你要遵守这些政策，如果有人违规的话，违反了这个政策，你就要去修补你的这个漏洞。</p><p>我和的同事在微软研究院所做的，我们会看一下在人们遵守这个公共政策的规模和程度是如何。这涉及到我们编程的语言，我们做成数据地图，这个数据地图每天晚上在微软进行运行，帮我们找到我们政策上的漏洞，所以自动化可以在这方面帮助我们，让我们负起责任来，让我们对于我们发布的政策负起责任来。</p><p>152层的DNN如何保障其透明度？</p><p>第三个关键词是透明度。</p><p>透明度现在是一个很大的问题，特别是我们涉及到这些深层的神经网络的时候，我们是否应该对这个结果予以信任，我们为什么要对这个结果予以信任呢，我们都不知道怎么样来运作的，从这个科学的角度来说，我们其实并不了解他们是如何来工作的，那这样的话，就会引起一些问题。</p><p>在给大家举例子之前，首先给大家介绍一下，我们最大的DNN（音），这是152层的DNN，那么它是获得了2015年的Image.net的竞赛奖项，这里面我们可以看到这里的DNN一共有152层，大家问为什么是要152层，事实上我们不知道为什么是152层，结果就是如此，对于科学家来讲，我们不仅仅满足于这个答案，我们看这个DNN在什么情况下会出错。</p><p>哥伦比亚教授周以真：人工智能恐慌以及大数据威胁反思<br>这个例子看出来，我们为什么使用这个DNN的时候，做图象识别的时候，要小心，这是一段视频，在这个视频当中，我们可以看到，我们在驾驶车辆，我们开车的时候，可以看到有一个车速限速度的标志，在右侧可以看到，在右边是停止的Stop的牌子，在左边是涂鸦的限速45英里的牌子，这个DNN识别到在右侧Stop的图像。它认为有了这个涂鸦的限速牌，不认为这是一个限速牌，在开车不到一秒的时间里面，我们可以看到后面驾驶的车辆，开得很近的时候，发现涂鸦的这个标牌也是Stop的标牌，但是看见的时候已经太迟了，他觉得这个时候要刹车已经来不及了，这时候就有可能发生撞车的事故。</p><p>现在不光是熊猫、猴子，还有刚才我们所提的这样一些例子，这个就是大家可以看到的，如果我们对于这个DNN怎样工作的原理不清楚的话，就会潜在的造成一些威胁。</p><p>我们再来看一个例子。我们可以看到奥巴马在同样一个音轨，同样的话，用四种语音语段发出来，这是一个Youtube上面比较好玩的事情。对于这样一个音频流，你可以知道任何人都可以模拟任何人的发音，这样就会产生威胁。</p><p>阿里巴巴这样的大公司应该怎么做？</p><p>这不单会产生技术问题，也不是写论文的问题，应该说这是一个实实在在的，对于大公司，比方说像阿里巴巴这样的大公司，正在努力致力于研究解决的这样一些问题。欧盟也有这样的政策，2018年所有大的公司，都要遵守这样的一个有关于数据方面的问题的法规章程，不然的话，你就会被罚款或者说有4%这样的营业收入就要来交营业罚款。</p><p>这里有四个标准，一个是可访问的权利，一个是可忘却的权力，一个是数据的可携带性，还有可解释的权利，2017年到2018年之间，科学家正在致力于了解深度学习到底是怎么样来进行工作的，要能够解释得清，这是一个伦理的问题。</p><p>这里面我们可以看到，这里是一个列车的问题，我们可以看到这里面一辆列车开过来，扳这里有一个选择，到底是通过扳道，是往上面的通道走还是往下面的通道走，下面可能是小孩子或者说肥胖的人，不管是把道路往哪个方向搬，这都会牵涉到伦理方面的难题。那么现在有了我们这个自动驾驶车，必须要做这样的决定，比方说在碰到类似情况的时候，这个车应该做什么样的决断。比方说在右边有一个行人，但是这个人比方说在人行道上面也有其他的人，这个车躲避的话，到底是躲避谁，撞上什么，这是很难下的决定。</p><p>这是一个假新闻的问题，那么假新闻现在也在美国到处肆虐，这里应该说假新闻泛滥，造成了很多的问题，我们大家看到微软有这样一个例子，一个聊天机器人，叫做小兵，这个聊天机器人是如此的流行，以至于在美国，我们有一点嫉妒，你们中国有这样的很好的聊天机器人，在美国还没有这么好的聊天机器人，去年微软也有了这么一个聊天机器人。</p><p>我们在24小时之内，不得不把这个聊天机器人关闭了，为什么呢？因为我们看到由于互联网之间有一些阴暗面的存在，很快我们发现聊天机器人被诱导，引导说一些很不好听的话题，这里面我们才认识到互联网，这里面也有一些快速传播的不良信息，我们要非常重视伦理道德，我们在设计的时候就要注意，而不是在运用的时候。</p><p>还有一个例子是关于安全和保密的事情，例如天猫精灵，在你家或者车里，很容易被黑客侵入，所以物联网这样的平台，如果说连到互联网这样任何的物品，很容易被坏人所侵入，这样就会造成一些影响。</p><p>如何用科技保证科技本身的公平透明？</p><p>回过头来再看一下缩写拼出的词，FATEC代表公平、透明等等，在这方面，科技能够做哪些工作呢？</p><p>我们可以看到刚才所说的，应该要产出各种可能性，有各种各样的模式模板，所以我们要让第三方别人能够来检查我们这样的一些产品，同样的道理，比如说给他们提供这样一些资料和数据，我和我的两个同事也写过一篇论文，大家有兴趣的话，也可以阅读一下，比方说你的数据谁在掌握，我们现在有很多这样的科技公司，可以看到这样一些科技公司都是尽量在确保想要把人工智能、数据往好的方面运用。</p><p>比如说亚马逊、深度思考，包括苹果、IBM、Google、脸书等等机构，现在都有更多的机构和个人，都加入进来。人工智能能够造福人类，但是我们在科技界应该承担这样的责任，能够确保往好的方面来发展，我们现在也有一些新的问题。</p><p>我们现在已经对机器人有相关的立法，对人工智能是否也要立法，那么人工智能是不是也要进行很好的管制，包括这样一些平台，包括一些使用，人工智能的这样一些管道，是否也应该进行管制呢，如果要管制的话，是由谁来管制呢，我们是否要有一个消费者保护，有一个保险，还有比方说一些经济上面的奖励，以避免这样一些人工智能不良的应用。</p><p>包括我们所有的产品是否需要有一个授权许可，公司是否也需要有这样一个委员会专门来进行检查和审核。所以我们对于这个数据有一个负责任的态度来使用，才能够物尽其用，谢谢。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;哥伦比亚教授周以真：人工智能恐慌以及大数据威胁反思&lt;/p&gt;
&lt;p&gt;使用不负责任的数据导致的偏见算法和严重后果，到底应该由谁负责？个人和阿里巴巴这样的企业应该用什么样的态度对待数据？以及我们该如何用科技本身保证科技的公平透明？&lt;br&gt;大数据文摘记者：魏子敏&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="互联网资讯" scheme="http://yoursite.com/categories/%E4%BA%92%E8%81%94%E7%BD%91%E8%B5%84%E8%AE%AF/"/>
    
    
      <category term="资讯" scheme="http://yoursite.com/tags/%E8%B5%84%E8%AE%AF/"/>
    
  </entry>
  
</feed>
